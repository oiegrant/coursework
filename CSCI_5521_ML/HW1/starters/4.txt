import numpy as np

def Bayes_Learning(training_data, validation_data):
    """
    Function to perform Bayes learning on the given training data and validation data.
    
    Parameters:
        training_data (numpy array): A 2D numpy array containing the training data
                                     where each row corresponds to a data point and
                                     each column corresponds to a feature.
        validation_data (numpy array): A 2D numpy array containing the validation data
                                       where each row corresponds to a data point and
                                       each column corresponds to a feature.
    
    Returns:
        p1 (numpy array): A 1D numpy array containing the learned Bernoulli parameters
                          of the first class.
        p2 (numpy array): A 1D numpy array containing the learned Bernoulli parameters
                          of the second class.
        pc1 (float): The best prior of the first class.
        pc2 (float): The best prior of the second class.
    """
    # Separate the training data into two classes
    class_1_data = training_data[training_data[:, -1] == 1, :-1]
    class_2_data = training_data[training_data[:, -1] == 2, :-1]
    
    # Calculate the learned Bernoulli parameters for each class
    p1 = np.mean(class_1_data, axis=0)
    p2 = np.mean(class_2_data, axis=0)
    
    # Calculate the error rate for each possible prior value on the validation data
    prior_values = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 2, 3, 4, 5, 6]
    error_rates = []
    for prior in prior_values:
        # Calculate the prior probabilities of each class
        pc1 = 1 - np.exp(-prior)
        pc2 = 1 - pc1
        
        # Calculate the posterior probabilities for each data point in the validation data
        posteriors = np.zeros((validation_data.shape[0], 2))
        posteriors[:, 0] = np.sum(np.log(np.where(validation_data[:, :-1] == 1, p1, 1 - p1)), axis=1) + np.log(pc1)
        posteriors[:, 1] = np.sum(np.log(np.where(validation_data[:, :-1] == 1, p2, 1 - p2)), axis=1) + np.log(pc2)
        
        # Classify the validation data using the maximum posterior probability
        classifications = np.argmax(posteriors, axis=1) + 1
        
        # Calculate the error rate
        error_rate = np.mean(classifications != validation_data[:, -1])
        error_rates.append(error_rate)
    
    # Find the best prior that gives the lowest error rate on the validation data
    best_prior_idx = np.argmin(error_rates)
    pc1 = 1 - np.exp(-prior_values[best_prior_idx])
    pc2 = 1 - pc1
    
    # Print a table of error rates for all priors
    print("Prior Value\tError Rate")
    for i in range(len(prior_values)):
        print("{:.6f}\t\t{:.6f}".format(prior_values[i], error_rates[i]))
    
    return p1, p2, pc1, pc2

###################################################################################
//This function takes in the test data as well as the learned Bernoulli parameters and priors from the training phase, and classifies each sample in the test data using the learned distributions and priors. It then calculates the error rate of classification and prints it to the console.


import numpy as np

def Bayes_Testing(test_data, p1, p2, pc1, pc2):
    """
    Classifies the samples in the test set using the learned Bernoulli distributions and given priors.
    Returns the error rate of classification.
    
    Args:
    test_data (ndarray): A 2D numpy array of shape (N, M) where N is the number of samples and M is the number of features.
    p1 (ndarray): A 1D numpy array of shape (M,) representing the learned Bernoulli parameters of class 1.
    p2 (ndarray): A 1D numpy array of shape (M,) representing the learned Bernoulli parameters of class 2.
    pc1 (float): The best prior of class 1.
    pc2 (float): The best prior of class 2.
    
    Returns:
    float: The error rate of classification.
    """
    # Convert p1 and p2 to log scale to avoid underflow errors
    log_p1 = np.log(p1)
    log_p2 = np.log(p2)
    
    # Calculate the log likelihoods of each class for each sample
    log_likelihoods_c1 = (test_data @ log_p1 + (1 - test_data) @ np.log(1 - np.exp(log_p1)))
    log_likelihoods_c2 = (test_data @ log_p2 + (1 - test_data) @ np.log(1 - np.exp(log_p2)))
    
    # Calculate the log posterior probabilities of each class for each sample
    log_posterior_c1 = log_likelihoods_c1 + np.log(pc1)
    log_posterior_c2 = log_likelihoods_c2 + np.log(pc2)
    
    # Classify each sample based on the class with the highest posterior probability
    predicted_labels = np.argmax(np.vstack((log_posterior_c1, log_posterior_c2)).T, axis=1)
    
    # Calculate the error rate
    true_labels = test_data[:, -1].astype(int)
    error_rate = np.sum(predicted_labels != true_labels) / len(true_labels)
    
    # Print the error rate to the console
    print("Test Error Rate: {:.2f}%".format(error_rate * 100))
    
    return error_rate


############################################

/*This script first loads the training, validation, and test data using numpy.loadtxt(). It then calls the Bayes_Learning() function from Bayes_learning.py to get the learned parameters and best priors for the classification problem. The error rates for each value of sigma are stored in the error_rates variable and printed to the console in a table.

Finally, the script calls the Bayes_Testing() function from Bayes_testing.py to get the error rate on the test data, and prints the result to the console.*/


import numpy as np
from Bayes_learning import Bayes_Learning
from Bayes_testing import Bayes_Testing

# Load data
training_data = np.loadtxt('train.txt')
validation_data = np.loadtxt('validate.txt')
test_data = np.loadtxt('test.txt')

# Call Bayes Learning to get learned parameters and best priors
p1, p2, pc1, pc2, error_rates = Bayes_Learning(training_data, validation_data)

# Print error rate table
print("Error Rates:")
print("Ïƒ\tError Rate")
for i, sigma in enumerate([0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 2, 3, 4, 5, 6]):
    print(f"{sigma}\t{error_rates[i]}")

# Call Bayes Testing to get error rate on test data
test_error_rate = Bayes_Testing(test_data, p1, p2, pc1, pc2)
print(f"Error rate on test data: {test_error_rate}")

